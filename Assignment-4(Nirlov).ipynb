{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed898c32-e6e3-4adf-ba0e-8832aea309f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9eb8eef-18bc-4acd-80dc-aa0ce93df232",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255,zoom_range=0.2,horizontal_flip=True,vertical_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1f3953e-75ee-4569-8739-f178c6a3f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34485362-ace5-44c2-9587-ae25f33297f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2527 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train=train_datagen.flow_from_directory(r'C:\\Users\\LEGION\\Desktop\\Externship_SmartBridge\\Assignment-4 dataset\\Garbage classification\\Garbage classification',target_size=(64,64),\n",
    "                                          class_mode='categorical',batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98726e9c-8965-4123-9e20-bb313b1292f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61560dcc-45cb-4b3f-970e-8925f44de37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cardboard': 0, 'glass': 1, 'metal': 2, 'paper': 3, 'plastic': 4, 'trash': 5}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7312e1-7e4e-4461-9b81-1182384eceb9",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07b5fc18-93ae-4931-a79f-14d4e2e25f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cc9018-a0b5-40a7-86cc-45bcd2c628c0",
   "metadata": {},
   "source": [
    "Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d21d81b-db1f-4fd0-baa5-04d30afc0eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdba2e08-a486-4e1d-b1c4-a64f513ff1d5",
   "metadata": {},
   "source": [
    "Adding Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2871e6f-0c96-4ca3-a461-34dd881ef83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32,(3,3),activation='relu',input_shape=(64,64,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9734223-425c-4dbb-8464-d5bdec6a8660",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "802dd557-86ff-42e2-9431-6316d4973e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ccc2591-21eb-41d4-8239-1dd53c1fd6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Hidden Layer 1\n",
    "model.add(Dense(300,activation='relu'))\n",
    "##Hidden Layer 2\n",
    "model.add(Dense(150,activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e291b0-0261-40f1-8d8e-31c06704dcdc",
   "metadata": {},
   "source": [
    "Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d888189-08f2-4a62-a1bf-44f4571af030",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(6,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83d3994-4222-4231-ada0-5c8ae01255e2",
   "metadata": {},
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "512ce664-340e-4386-955e-4328e75bb992",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bdd40d-2854-446e-a7e0-4d7961b0acdd",
   "metadata": {},
   "source": [
    "Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5579ab3-98c1-45b9-934c-c3791bb28796",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\AppData\\Local\\Temp/ipykernel_19604/3129788946.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(x_train,steps_per_epoch=len(x_train),epochs=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "26/26 [==============================] - 10s 363ms/step - loss: 2.9562 - accuracy: 0.2074\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 11s 406ms/step - loss: 1.5404 - accuracy: 0.3716\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 11s 415ms/step - loss: 1.3719 - accuracy: 0.4575\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 11s 425ms/step - loss: 1.2741 - accuracy: 0.4931\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 11s 403ms/step - loss: 1.2261 - accuracy: 0.5307\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 10s 396ms/step - loss: 1.1494 - accuracy: 0.5647\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 11s 403ms/step - loss: 1.1115 - accuracy: 0.5861\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 11s 405ms/step - loss: 1.0683 - accuracy: 0.5904\n",
      "Epoch 9/10\n",
      "17/26 [==================>...........] - ETA: 3s - loss: 0.9907 - accuracy: 0.6318"
     ]
    }
   ],
   "source": [
    "model.fit_generator(x_train,steps_per_epoch=len(x_train),epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928c11bc-dbb2-41b8-8330-c86a9ec80eb4",
   "metadata": {},
   "source": [
    "Save the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a93dc5f-5a16-4c87-99dc-cfa9c9452651",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('garbage.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e4ae8b-2e8b-46f8-a2f3-c66e1b6b7f47",
   "metadata": {},
   "source": [
    "Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef356a3-ed51-4d25-8633-d5e409b37b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134eeff4-f787-4852-a078-04ae935b1775",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('garbage.h5')\n",
    "img=image.load_img(r'C:\\Users\\LEGION\\Desktop\\Externship_SmartBridge\\Assignment-4 dataset\\Garbage classification\\Garbage classification\\glass\\glass19.jpg',\n",
    "                   target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940f1ab6-7f66-4e84-b118-001ac7a15c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a251aff-3eff-4444-9dd1-2385e0162e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52314d7-17e9-41ce-acdb-cf4daaa51895",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dc2614-ead3-4e78-a56f-4ed1a1891247",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2df915-501f-4391-8489-1be1a2683d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.expand_dims(x,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3ca212-1ca2-46da-88d2-a386db7d598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9419862-58de-4582-9cf4-96431fe888ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a6bd47-8321-4096-aa81-49387183d8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=np.argmax(model.predict(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a586b3-e47b-42c0-ba2f-d7d0515cc803",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5839ce-cb2b-4328-9cf1-3d5192eaa3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "index=['cardboard','glass','metal','paper','plastic','trash']\n",
    "print(index[pred[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aa19a9-5036-4d45-b0ad-b41cad3d4160",
   "metadata": {},
   "source": [
    "Open CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d5203b-898b-46f3-aaad-4fceecc5675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97d7779-9070-49c2-88c5-394361f33e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(r'C:\\Users\\LEGION\\Desktop\\Externship_SmartBridge\\Assignment-4 dataset\\Garbage classification\\Garbage classification\\glass\\glass19.jpg',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9020698a-390f-4c27-9c6d-d81a4592b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700e0b1b-cc23-46ed-ae81-935287df2112",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1=cv2.imread(r'C:\\Users\\LEGION\\Desktop\\Externship_SmartBridge\\Assignment-4 dataset\\Garbage classification\\Garbage classification\\glass\\glass19.jpg',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469d8ba4-4aa4-4c5a-888c-accd837d1054",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc89e001-b481-4a1c-9e2f-64d2009abdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ac0166-322b-4f49-9718-40782e10e411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c8c546-c270-4947-89c4-34262be7aab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(r'C:\\Users\\LEGION\\Desktop\\Externship_SmartBridge\\Assignment-4 dataset\\Garbage classification\\Garbage classification\\glass\\glass19.jpg',1)\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c774a58-042c-4d73-9b73-7b409159d10b",
   "metadata": {},
   "source": [
    "CNN Video Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030d7f7f-cc5b-4371-bea0-7afe84d97ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "model=load_model('garbage.h5')\n",
    "video=cv2.VideoCapture(0)\n",
    "index=['cardboard','glass','metal','paper','plastic','trash']\n",
    "while 1:\n",
    "    succes,frame=video.read()\n",
    "    cv2.imwrite('image.jpg',frame)\n",
    "    img=image.load_img('image.jpg',target_size=(64,64))\n",
    "    x=image.img_to_array(img)\n",
    "    x=np.expand_dims(x,axis=0)\n",
    "    pred=np.argmax(model.predict(x),axis=1)\n",
    "    y=pred[0]\n",
    "    cv2.putText(frame,'The Predicted Garbage is: '+str(index[y]),(100,100),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,0),4)\n",
    "    cv2.imshow('image',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "video.release()\n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4d1591-1a3f-4add-a351-e433ba9dd113",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
